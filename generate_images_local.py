"""
Generador de im√°genes LOCAL usando tu GPU
Usa Stable Diffusion ejecut√°ndose en tu m√°quina
"""

import torch
from diffusers import StableDiffusionPipeline
from PIL import Image
import os
from datetime import datetime


def check_system():
    """Verificar sistema"""
    print("\n" + "="*60)
    print("üîç VERIFICANDO SISTEMA")
    print("="*60)
    
    print(f"‚úì PyTorch: {torch.__version__}")
    
    if torch.cuda.is_available():
        print(f"‚úì CUDA disponible")
        print(f"  GPU: {torch.cuda.get_device_name(0)}")
        mem_gb = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"  Memoria: {mem_gb:.1f} GB")
        
        if mem_gb < 4:
            print("\n‚ö†Ô∏è  Advertencia: GPU con poca memoria")
            print("   Usa resoluci√≥n baja (512x512)")
        
        return True
    else:
        print("‚ùå No hay GPU disponible")
        print("üí° Se usar√° CPU (ser√° MUY lento, 5-10 minutos por imagen)")
        
        choice = input("\n¬øContinuar con CPU? (s/n): ").strip().lower()
        return choice in ['s', 'si', 's√≠', 'y', 'yes']


class LocalImageGenerator:
    """Generador 100% local usando tu GPU"""
    
    def __init__(self, model_id="runwayml/stable-diffusion-v1-5"):
        """
        Inicializar generador local
        
        Modelos disponibles:
        - "runwayml/stable-diffusion-v1-5" (m√°s r√°pido, 4GB RAM)
        - "stabilityai/stable-diffusion-2-1" (mejor calidad, 6GB RAM)
        """
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        print(f"\nüé® Cargando modelo de generaci√≥n...")
        print(f"üì¶ Modelo: {model_id}")
        print(f"üì± Device: {self.device}")
        print(f"\n‚è≥ Primera vez: descargar√° ~4-5 GB (puede tardar)")
        print("   Las siguientes veces ser√° instant√°neo\n")
        
        # Cargar pipeline
        try:
            self.pipe = StableDiffusionPipeline.from_pretrained(
                model_id,
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                safety_checker=None,
            )
            
            self.pipe = self.pipe.to(self.device)
            
            # Optimizaciones para GPU
            if self.device == "cuda":
                self.pipe.enable_attention_slicing()
                print("‚úì Optimizaciones de GPU activadas")
            
            print("‚úì Modelo cargado y listo!\n")
            
        except Exception as e:
            print(f"\n‚ùå Error al cargar modelo: {e}")
            print("\nüí° Soluciones:")
            print("   1. Instalar dependencias: pip install diffusers transformers accelerate")
            print("   2. Verificar conexi√≥n a internet (primera descarga)")
            print("   3. Liberar memoria GPU si est√° llena")
            raise
    
    def generate(
        self,
        prompt,
        negative_prompt="low quality, blurry, distorted, ugly",
        width=512,
        height=512,
        num_inference_steps=30,
        guidance_scale=7.5,
        seed=None
    ):
        """
        Generar imagen localmente en tu GPU
        
        Args:
            prompt: Descripci√≥n en ingl√©s
            negative_prompt: Qu√© evitar
            width/height: Resoluci√≥n (512 recomendado para 4GB GPU)
            num_inference_steps: Calidad (20-50, m√°s = mejor)
            guidance_scale: Literalidad (7-15)
            seed: Para reproducibilidad
        """
        print(f"üé® Generando imagen LOCALMENTE en {self.device.upper()}...")
        print(f"üìù Prompt: {prompt}")
        print(f"‚öôÔ∏è  Resoluci√≥n: {width}x{height}")
        print(f"‚öôÔ∏è  Pasos: {num_inference_steps}")
        
        generator = None
        if seed is not None:
            generator = torch.Generator(device=self.device).manual_seed(seed)
        
        try:
            # Generar
            with torch.autocast(self.device):
                result = self.pipe(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    width=width,
                    height=height,
                    num_inference_steps=num_inference_steps,
                    guidance_scale=guidance_scale,
                    generator=generator
                )
            
            print("‚úì Generaci√≥n completada!")
            return result.images
        
        except torch.cuda.OutOfMemoryError:
            print("\n‚ùå Error: GPU sin memoria suficiente")
            print("üí° Soluciones:")
            print("   1. Reduce resoluci√≥n: --width 448 --height 448")
            print("   2. Reduce steps: --steps 20")
            print("   3. Cierra otras aplicaciones que usen GPU")
            return None
        except Exception as e:
            print(f"\n‚ùå Error: {e}")
            return None
    
    def save_image(self, image, output_dir="outputs/generated"):
        """Guardar imagen"""
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"local_generated_{timestamp}.png"
        filepath = os.path.join(output_dir, filename)
        
        image.save(filepath)
        print(f"‚úì Guardada: {filepath}")
        
        return filepath


def main():
    """Funci√≥n principal"""
    print("\n" + "üé® "*20)
    print("   GENERADOR LOCAL DE IM√ÅGENES")
    print("   100% en tu GPU - Sin APIs externas")
    print("üé® "*20)
    
    # Verificar sistema
    if not check_system():
        print("\n‚ùå Cancelado")
        return
    
    # Verificar dependencias
    try:
        import diffusers
        import transformers
    except ImportError:
        print("\n‚ùå Faltan dependencias")
        print("\nüí° Instalar con:")
        print("   pip install diffusers transformers accelerate")
        return
    
    # Inicializar generador
    try:
        generator = LocalImageGenerator()
    except Exception as e:
        print(f"\n‚ùå No se pudo inicializar el generador")
        return
    
    print("="*60)
    print("üìù TIPS:")
    print("="*60)
    print("‚Ä¢ Escribe en INGL√âS para mejores resultados")
    print("‚Ä¢ S√© espec√≠fico y descriptivo")
    print("‚Ä¢ Ejemplos:")
    print("  'a beautiful cat, digital art, highly detailed'")
    print("  'mountain landscape at sunset, photorealistic'")
    print("="*60 + "\n")
    
    while True:
        try:
            prompt = input("üìù Describe la imagen (o 'exit'): ").strip()
            
            if prompt.lower() in ['exit', 'salir', 'quit']:
                print("\nüëã ¬°Hasta luego!")
                break
            
            if not prompt:
                print("‚ùå Prompt vac√≠o\n")
                continue
            
            # Configuraci√≥n r√°pida
            print("\n‚öôÔ∏è  ¬øUsar valores por defecto? (s/n):", end=" ")
            use_defaults = input().strip().lower() in ['s', 'si', 's√≠', 'y', 'yes', '']
            
            if use_defaults:
                width, height = 512, 512
                steps = 30
                guidance = 7.5
            else:
                try:
                    width = int(input("  Ancho [512]: ") or 512)
                    height = int(input("  Alto [512]: ") or 512)
                    steps = int(input("  Pasos [30]: ") or 30)
                    guidance = float(input("  Guidance [7.5]: ") or 7.5)
                except ValueError:
                    width, height, steps, guidance = 512, 512, 30, 7.5
            
            # Generar
            print()
            images = generator.generate(
                prompt=prompt,
                width=width,
                height=height,
                num_inference_steps=steps,
                guidance_scale=guidance
            )
            
            if images:
                # Guardar
                print()
                filepath = generator.save_image(images[0])
                
                print(f"\n‚úÖ ¬°Imagen generada LOCALMENTE!")
                print(f"üìÅ Ubicaci√≥n: {filepath}")
                
                # Abrir
                open_choice = input("\n¬øAbrir imagen? (s/n): ").strip().lower()
                if open_choice in ['s', 'si', 's√≠', 'y', 'yes']:
                    os.system(f"xdg-open {filepath} 2>/dev/null || open {filepath} 2>/dev/null")
            
            # Continuar
            print()
            if input("¬øOtra imagen? (s/n): ").strip().lower() not in ['s', 'si', 's√≠', 'y', 'yes']:
                break
            print()
        
        except KeyboardInterrupt:
            print("\n\nüëã Cancelado")
            break
        except Exception as e:
            print(f"\n‚ùå Error: {e}")


if __name__ == "__main__":
    main()
