"""
Generador de imÃ¡genes con IA usando Stable Diffusion
Requiere: pip install diffusers transformers accelerate torch pillow
"""

import torch
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
from PIL import Image
import os
from datetime import datetime


class ImageGenerator:
    """Generador de imÃ¡genes con IA"""
    
    def __init__(self, model_id="stabilityai/stable-diffusion-2-1", device=None):
        """
        Inicializar generador
        
        Args:
            model_id: ID del modelo en Hugging Face
            device: 'cuda' o 'cpu' (None = auto-detect)
        """
        if device is None:
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device
        
        print(f"ğŸ¨ Inicializando generador de imÃ¡genes...")
        print(f"ğŸ“± Device: {self.device}")
        
        # Cargar pipeline
        self.pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
            safety_checker=None,  # Opcional: remover para contenido sensible
        )
        
        # Optimizar scheduler para mejor calidad y velocidad
        self.pipe.scheduler = DPMSolverMultistepScheduler.from_config(
            self.pipe.scheduler.config
        )
        
        # Mover a GPU
        self.pipe = self.pipe.to(self.device)
        
        # Optimizaciones si hay GPU
        if self.device == "cuda":
            self.pipe.enable_attention_slicing()
            # self.pipe.enable_xformers_memory_efficient_attention()  # Descomentar si tienes xformers
        
        print("âœ“ Generador listo!\n")
    
    def generate(
        self,
        prompt,
        negative_prompt="low quality, blurry, distorted, ugly, bad anatomy",
        num_images=1,
        width=512,
        height=512,
        num_inference_steps=50,
        guidance_scale=7.5,
        seed=None
    ):
        """
        Generar imagen desde texto
        
        Args:
            prompt: DescripciÃ³n de la imagen en inglÃ©s
            negative_prompt: QuÃ© evitar en la imagen
            num_images: Cantidad de imÃ¡genes a generar
            width: Ancho (mÃºltiplo de 8, recomendado: 512-768)
            height: Alto (mÃºltiplo de 8, recomendado: 512-768)
            num_inference_steps: Pasos de generaciÃ³n (mÃ¡s = mejor calidad, mÃ¡s lento)
            guidance_scale: QuÃ© tan literal seguir el prompt (7-15)
            seed: Semilla para reproducibilidad
        
        Returns:
            Lista de imÃ¡genes PIL
        """
        # Configurar semilla si se proporciona
        generator = None
        if seed is not None:
            generator = torch.Generator(device=self.device).manual_seed(seed)
        
        print(f"ğŸ¨ Generando {num_images} imagen(es)...")
        print(f"ğŸ“ Prompt: {prompt}")
        print(f"âš™ï¸  Pasos: {num_inference_steps}, Guidance: {guidance_scale}")
        
        # Generar
        with torch.autocast(self.device):
            result = self.pipe(
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_images_per_prompt=num_images,
                width=width,
                height=height,
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale,
                generator=generator
            )
        
        return result.images
    
    def save_images(self, images, output_dir="outputs/generated", prefix="ai_generated"):
        """Guardar imÃ¡genes generadas"""
        os.makedirs(output_dir, exist_ok=True)
        
        saved_paths = []
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        for i, image in enumerate(images):
            filename = f"{prefix}_{timestamp}_{i+1}.png"
            filepath = os.path.join(output_dir, filename)
            image.save(filepath)
            saved_paths.append(filepath)
            print(f"âœ“ Guardada: {filepath}")
        
        return saved_paths


def main():
    """FunciÃ³n principal"""
    print("\n" + "ğŸ¨ "*20)
    print("   GENERADOR DE IMÃGENES CON IA")
    print("ğŸ¨ "*20 + "\n")
    
    # Verificar GPU
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"âœ“ GPU detectada: {gpu_name} ({gpu_memory:.1f} GB)")
    else:
        print("âš ï¸  No hay GPU, se usarÃ¡ CPU (serÃ¡ MUY lento)")
        print("ğŸ’¡ Recomendado: Usar GPU o servicios en la nube\n")
    
    # Inicializar generador
    try:
        generator = ImageGenerator()
    except Exception as e:
        print(f"\nâŒ Error al cargar modelo: {e}")
        print("\nğŸ’¡ Instala dependencias:")
        print("   pip install diffusers transformers accelerate")
        return
    
    print("="*60)
    print("ğŸ“ INSTRUCCIONES:")
    print("="*60)
    print("â€¢ Escribe en INGLÃ‰S para mejores resultados")
    print("â€¢ SÃ© especÃ­fico y descriptivo")
    print("â€¢ Ejemplos:")
    print("  - 'a beautiful sunset over mountains, digital art'")
    print("  - 'portrait of a cat wearing sunglasses, photorealistic'")
    print("  - 'futuristic city with flying cars, cyberpunk style'")
    print("="*60 + "\n")
    
    while True:
        try:
            prompt = input("ğŸ“ Describe la imagen (o 'exit' para salir): ").strip()
            
            if prompt.lower() in ['exit', 'salir', 'quit']:
                print("\nğŸ‘‹ Â¡Hasta luego!")
                break
            
            if not prompt:
                print("âŒ Prompt vacÃ­o, intenta de nuevo\n")
                continue
            
            # Preguntar configuraciÃ³n
            print("\nâš™ï¸  ConfiguraciÃ³n (presiona Enter para usar valores por defecto):")
            
            try:
                num_images = input("  Cantidad de imÃ¡genes [1]: ").strip()
                num_images = int(num_images) if num_images else 1
                
                steps = input("  Pasos de inferencia [30]: ").strip()
                steps = int(steps) if steps else 30
                
                guidance = input("  Guidance scale [7.5]: ").strip()
                guidance = float(guidance) if guidance else 7.5
            except ValueError:
                print("âš ï¸  Valor invÃ¡lido, usando valores por defecto")
                num_images = 1
                steps = 30
                guidance = 7.5
            
            # Generar
            print()
            images = generator.generate(
                prompt=prompt,
                num_images=num_images,
                num_inference_steps=steps,
                guidance_scale=guidance
            )
            
            # Guardar
            print()
            saved_paths = generator.save_images(images)
            
            print(f"\nâœ… Â¡Listo! {len(images)} imagen(es) generada(s)")
            print(f"ğŸ“ Guardadas en: outputs/generated/\n")
            
            # Preguntar si continuar
            continue_choice = input("Â¿Generar otra imagen? (s/n): ").strip().lower()
            if continue_choice not in ['s', 'si', 'sÃ­', 'y', 'yes']:
                print("\nğŸ‘‹ Â¡Hasta luego!")
                break
            print()
        
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Cancelado por usuario")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}")
            import traceback
            traceback.print_exc()
            print()


if __name__ == "__main__":
    main()
